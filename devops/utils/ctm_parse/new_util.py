# å¯¼å…¥SQLAlchemyç›¸å…³ç»„ä»¶ï¼Œç”¨äºæ•°æ®åº“æ“ä½œ
from sqlalchemy import create_engine, Column, Integer, String, JSON, ForeignKey, Text, select, ARRAY, or_, MetaData, \
    text
from sqlalchemy.orm import relationship, scoped_session, declarative_base, aliased
from sqlalchemy.orm.session import sessionmaker
# å¯¼å…¥lxmlçš„etreeæ¨¡å—ï¼Œç”¨äºXMLå¤„ç†
from lxml import etree as ET
import time
import os
import networkx as nx
import pandas as pd
from py2neo import Graph, Node, Relationship

# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URI = 'postgresql://fastapi:fastapi-root@10.124.160.153/fastapi'

# åˆ›å»ºæ•°æ®åº“å¼•æ“
engine = create_engine(DATABASE_URI)
# åˆ›å»ºä¼šè¯å·¥å‚ï¼Œä½¿ç”¨scoped_sessionç¡®ä¿çº¿ç¨‹å®‰å…¨
Session = scoped_session(sessionmaker(bind=engine))
session = Session()

# åˆ›å»ºdeclarativeåŸºç±»ï¼Œç”¨äºå®šä¹‰ORMæ¨¡å‹
metadata = MetaData(schema="parser")
Base = declarative_base(metadata=metadata)


class ControlMObject(Base):
    """Control-Må¯¹è±¡æ¨¡å‹ï¼Œç”¨äºå­˜å‚¨ä½œä¸šã€æ–‡ä»¶å¤¹ç­‰å¯¹è±¡çš„åŸºæœ¬ä¿¡æ¯å’Œå±‚çº§å…³ç³»"""
    __tablename__ = 'controlm_objects'
    __table_args__ = {"schema": "parser"}
    # ä¸»é”®ID
    id = Column(Integer, primary_key=True)
    # çˆ¶å¯¹è±¡IDï¼Œç”¨äºæ„å»ºå±‚çº§å…³ç³»
    parent_id = Column(Integer, ForeignKey('controlm_objects.id'))
    # å¯¹è±¡ç±»å‹ï¼Œå¦‚JOBã€FOLDERç­‰
    object_type = Column(String, nullable=False)
    # å¯¹è±¡åç§°
    name = Column(String, nullable=False)
    # å¯¹è±¡å†…å®¹
    content = Column(String)
    # åœ¨å±‚çº§ç»“æ„ä¸­çš„çº§åˆ«
    hierarchy_level = Column(Integer)
    # åœ¨çˆ¶å¯¹è±¡ä¸­çš„ä½ç½®
    position_in_parent = Column(Integer)
    # å­å¯¹è±¡å…³ç³»ï¼Œcascadeç¡®ä¿åˆ é™¤çˆ¶å¯¹è±¡æ—¶åŒæ—¶åˆ é™¤å­å¯¹è±¡
    children = relationship("ControlMObject", back_populates="parent", cascade="all, delete-orphan")
    # çˆ¶å¯¹è±¡å…³ç³»
    parent = relationship("ControlMObject", back_populates="children", remote_side=[id])
    # å¯¹è±¡å±æ€§å…³ç³»ï¼ŒæŒ‰position_in_objectæ’åº
    attributes = relationship("ControlMAttribute", order_by="ControlMAttribute.position_in_object",
                              back_populates="object")


class ControlMAttribute(Base):
    """Control-Må¯¹è±¡çš„å±æ€§æ¨¡å‹ï¼Œç”¨äºå­˜å‚¨å¯¹è±¡çš„å„ç§å±æ€§ä¿¡æ¯"""
    __tablename__ = 'controlm_attributes'
    __table_args__ = {"schema": "parser"}
    # ä¸»é”®ID
    id = Column(Integer, primary_key=True)
    # å…³è”çš„å¯¹è±¡ID
    object_id = Column(Integer, ForeignKey('controlm_objects.id'))
    # å±æ€§åç§°
    attribute_name = Column(String, nullable=False)
    # å±æ€§å€¼
    attribute_value = Column(String)
    # å±æ€§åœ¨å¯¹è±¡ä¸­çš„ä½ç½®é¡ºåº
    position_in_object = Column(Integer)
    # ä¸å¯¹è±¡çš„å…³è”å…³ç³»
    object = relationship("ControlMObject", back_populates="attributes")


class ControlMObjectWithAttr(Base):
    """Control-Må¯¹è±¡åŠå…¶ä¾èµ–å…³ç³»çš„è§†å›¾æ¨¡å‹ï¼Œç”¨äºå­˜å‚¨å¯¹è±¡çš„å®Œæ•´ä¿¡æ¯åŠå…¶ä¾èµ–é“¾"""
    __tablename__ = 'controlm_object_with_attr'
    __table_args__ = {"schema": "parser"}
    # ä¸»é”®ID
    id = Column(Integer, primary_key=True)
    # çˆ¶å¯¹è±¡ID
    parent_id = Column(Integer)
    # åº”ç”¨åç§°
    sub_application = Column(String, nullable=False)
    # å¯¹è±¡ç±»å‹
    object_type = Column(String, nullable=False)
    # å¯¹è±¡é€šç”¨åç§°
    general_name = Column(String, nullable=False)
    # ä¾èµ–ä½¿ç”¨åç§°
    dependency_name = Column(String, nullable=False)
    # å±‚çº§çº§åˆ«
    hierarchy_level = Column(Integer, nullable=False)
    # åœ¨çˆ¶å¯¹è±¡ä¸­çš„ä½ç½®
    position_in_parent = Column(Integer, nullable=False)
    # å¯¹è±¡çš„æ‰€æœ‰å±æ€§èšåˆä¸ºJSON
    json_object_agg = Column(JSON, nullable=False)
    # ä¸Šæ¸¸å¯¹è±¡åˆ—è¡¨
    from_object = Column(ARRAY(String), nullable=False)
    # ä¸‹æ¸¸å¯¹è±¡åˆ—è¡¨
    to_object = Column(ARRAY(String), nullable=False)


class ObjectExtend(Base):
    """CTMæ–‡ä»¶å¤¹ä¸ä½œä¸šå¯¹è±¡ - ç‰©åŒ–è§†å›¾å¯¹è±¡æ˜ å°„"""
    __tablename__ = "object_extend"
    __table_args__ = {"schema": "parser"}

    id = Column(Integer, primary_key=True)  # å¯¹è±¡å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆä½œä¸šæˆ–æ–‡ä»¶å¤¹ï¼‰
    parent_id = Column(Integer)  # çˆ¶çº§å¯¹è±¡IDï¼ˆç”¨äºæ„å»ºå±‚çº§ç»“æ„ï¼‰
    sub_application = Column(String)  # æ‰€å±å­åº”ç”¨å
    object_type = Column(String)  # å¯¹è±¡ç±»å‹ï¼ˆå¦‚ï¼šJob, Folderï¼‰
    general_name = Column(String)  # é€šç”¨åç§°ï¼ˆç”¨äºå±•ç¤ºæˆ–æœç´¢ï¼‰
    schedule_time = Column(String)  # è®¡åˆ’è°ƒåº¦æ—¶é—´ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œä¾‹å¦‚â€œ12:00â€ï¼‰
    cyclic = Column(String)  # æ˜¯å¦ä¸ºå‘¨æœŸæ€§ä½œä¸š
    cyclic_type = Column(String)  # å‘¨æœŸæ€§ç±»å‹ï¼ˆå¦‚ DAILYã€HOURLY ç­‰ï¼‰
    time_from = Column(String)  # å‘¨æœŸæ€§ä½œä¸šèµ·å§‹æ—¶é—´
    rbc_type = Column(String)  # å…³è”çš„è§„åˆ™å‹æ—¥å†ç±»å‹ï¼ˆRule-Based Calendarï¼‰
    level = Column(Integer)  # å±‚çº§æ·±åº¦ï¼ˆç”¨äºæ ‘çŠ¶ç»“æ„å¯è§†åŒ–ï¼‰
    from_object = Column(String)  # ä¾èµ–å…³ç³»çš„èµ·ç‚¹å¯¹è±¡ï¼ˆå¦‚ä¾èµ–é“¾ä¸­çš„å‰é©±ä½œä¸šï¼‰
    to_object = Column(String)  # ä¾èµ–å…³ç³»çš„ç›®æ ‡å¯¹è±¡ï¼ˆå¦‚åç»§ä½œä¸šï¼‰
    is_schedule = Column(String)  # æ˜¯å¦å¯ç”¨è°ƒåº¦ï¼ˆ0 è¡¨ç¤ºæœªè°ƒåº¦ï¼‰
    folder_rbc_type = Column(String)  # æ–‡ä»¶å¤¹çº§åˆ«çš„è§„åˆ™æ—¥å†ç±»å‹
    appl_type = Column(String)  # åº”ç”¨ç±»å‹ï¼ˆå¦‚ Batchã€Real-time ç­‰ï¼‰


class ObjectImpact(Base):
    __tablename__ = 'object_impact'
    __table_args__ = {'schema': 'parser'}

    obj_id = Column(Integer, primary_key=True, comment="å¯¹è±¡å”¯ä¸€æ ‡è¯†")
    decendant_ids = Column(ARRAY(Integer), comment="æ‰€æœ‰ä¸‹æ¸¸èŠ‚ç‚¹")


class GetObjectRelation(Base):
    __tablename__ = 'get_object_relation'
    __table_args__ = {'schema': 'parser'}

    from_obj_id = Column(Integer, primary_key=True)  # å¦‚æœæ²¡æœ‰å”¯ä¸€é”®ï¼Œå¯ä»¥ä¸´æ—¶è®¾ä¸º composite ä¸»é”®
    from_obj_type = Column(String)
    to_obj_id = Column(Integer, primary_key=True)
    to_obj_type = Column(String)


def parse_xml_to_db(file_path, batch_size=10000):
    """
    ä»XMLæ–‡ä»¶è§£æControl-Mé…ç½®æ•°æ®å¹¶æ‰¹é‡æ’å…¥æ•°æ®åº“ã€‚
    é‡‡ç”¨é€’å½’æ–¹å¼å¤„ç†XMLçš„å±‚çº§ç»“æ„ï¼Œå¹¶ä½¿ç”¨æ‰¹é‡æ’å…¥æé«˜æ€§èƒ½ã€‚

    :param file_path: XMLæ–‡ä»¶è·¯å¾„
    :param batch_size: æ¯æ‰¹æ’å…¥çš„è¡Œæ•°ï¼Œé»˜è®¤ä¸º10000ï¼Œç”¨äºæ§åˆ¶å†…å­˜ä½¿ç”¨
    """
    # è§£æXMLæ–‡ä»¶
    tree = ET.parse(file_path)
    root = tree.getroot()
    # åˆå§‹åŒ–å¾…æ’å…¥çš„å¯¹è±¡å’Œå±æ€§åˆ—è¡¨
    objects_to_add = []
    attributes_to_add = []
    batch_count = 0

    table_lst = ['controlm_attributes','controlm_objects']
    for tab in table_lst:
        session.execute(text('TRUNCATE TABLE parser.' + tab + ';'))
        session.commit()
        print(tab + ' truncate done!')

    def _parse_element(element, parent_id, hierarchy_level):
        """é€’å½’è§£æXMLå…ƒç´ 

        :param element: å½“å‰å¤„ç†çš„XMLå…ƒç´ 
        :param parent_id: çˆ¶å¯¹è±¡çš„ID
        :param hierarchy_level: å½“å‰å±‚çº§æ·±åº¦
        """
        nonlocal batch_count

        # è·å–ä¸‹ä¸€ä¸ªå¯¹è±¡ID
        query = text("SELECT nextval('parser.seq_controlm_object_id') AS next_value")
        object_id = session.execute(query).scalar()

        # åˆ›å»ºControl-Må¯¹è±¡
        obj = ControlMObject(
            id=object_id,
            parent_id=parent_id,
            object_type=element.tag,  # ä½¿ç”¨XMLæ ‡ç­¾ä½œä¸ºå¯¹è±¡ç±»å‹
            name=element.attrib.get('NAME', ''),  # è·å–NAMEå±æ€§ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
            content=element.text.strip() if element.text else None,  # å¤„ç†æ–‡æœ¬å†…å®¹
            hierarchy_level=hierarchy_level,  # è®°å½•å±‚çº§æ·±åº¦
            position_in_parent=element.sourceline  # ä½¿ç”¨è¡Œå·ä½œä¸ºä½ç½®ä¿¡æ¯
        )

        objects_to_add.append(obj)

        # å¤„ç†å…ƒç´ çš„æ‰€æœ‰å±æ€§
        for idx, (attr_name, attr_value) in enumerate(element.attrib.items()):
            attr = ControlMAttribute(
                object_id=obj.id,
                attribute_name=attr_name,
                attribute_value=attr_value,
                position_in_object=idx  # ä¿æŒå±æ€§çš„åŸå§‹é¡ºåº
            )
            attributes_to_add.append(attr)

        batch_count += 1
        if batch_count >= batch_size:
            # è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æ—¶ï¼Œæ‰§è¡Œæ‰¹é‡æ’å…¥
            session.bulk_insert_mappings(ControlMObject, [obj.__dict__ for obj in objects_to_add])
            session.bulk_insert_mappings(ControlMAttribute, [attr.__dict__ for attr in attributes_to_add])
            session.commit()
            # æ¸…ç©ºåˆ—è¡¨å‡†å¤‡ä¸‹ä¸€æ‰¹æ•°æ®
            objects_to_add.clear()
            attributes_to_add.clear()
            batch_count = 0
            print(10000)  # æ‰“å°è¿›åº¦æŒ‡ç¤º

        # é€’å½’å¤„ç†æ‰€æœ‰å­å…ƒç´ 
        for child in element:
            _parse_element(child, parent_id=obj.id, hierarchy_level=hierarchy_level + 1)

    # ä»æ ¹èŠ‚ç‚¹å¼€å§‹è§£æ
    _parse_element(root, parent_id=None, hierarchy_level=0)

    # å¤„ç†æœ€åä¸€æ‰¹æœªæ»¡batch_sizeçš„æ•°æ®
    if objects_to_add or attributes_to_add:
        session.bulk_insert_mappings(ControlMObject, [obj.__dict__ for obj in objects_to_add])
        session.bulk_insert_mappings(ControlMAttribute, [attr.__dict__ for attr in attributes_to_add])
        session.commit()

    # æœ€ååˆ·æ–°ç‰©åŒ–è§†å›¾
    query = text("REFRESH MATERIALIZED VIEW parser.object_extend;")
    object_id = session.execute(query).scalar()

    print("è§£æå®Œæˆ")


def transform_to_graph():
    # åˆå§‹åŒ–æœ‰å‘å›¾
    graph = nx.DiGraph()

    def escape_quotes(value: str) -> str:
        return value.replace("'", "''") if value else ''

    def add_all_nodes():
        query = (
            select(ObjectExtend.id
                  ,ObjectExtend.sub_application
                  ,ObjectExtend.object_type
                  ,ObjectExtend.general_name
                  ,ObjectExtend.is_schedule
                  ,ObjectExtend.appl_type
                  ,ObjectExtend.time_from
                  ,ObjectExtend.cyclic
                  ,ObjectExtend.cyclic_type
                   )
            .where(ObjectExtend.sub_application.isnot(None))
        )
        object_list = session.execute(query).all()
        for obj in object_list:
            graph.add_node(obj.id,
                           obj_app=obj.sub_application,
                           obj_name=obj.general_name,
                           obj_type=obj.object_type,
                           is_schedule=obj.is_schedule,
                           appl_type=obj.appl_type,
                           time_from=obj.time_from,
                           cyclic=obj.cyclic,
                           cyclic_type=obj.cyclic_type
                           )
        print(f"âœ… æ·»åŠ èŠ‚ç‚¹æ•°ï¼š{graph.number_of_nodes()}")

    def add_folder_edges():
        print("ğŸ”¹ æ·»åŠ  FOLDER -> å­èŠ‚ç‚¹ å…³ç³»...")
        Parent = aliased(ObjectExtend)
        query = (
            select(Parent.id.label("prt_id"),
                   ObjectExtend.id.label("obj_id"))
            .join(Parent, ObjectExtend.parent_id == Parent.id, isouter=True)
            .where(Parent.object_type.isnot(None))
            .distinct()
        )
        relations = session.execute(query).all()
        for rel in relations:
            graph.add_edge(rel.prt_id, rel.obj_id, type='CONTAIN')
        print(f"âœ… å½“å‰æ€»è¾¹æ•°ï¼š{graph.number_of_edges()}")

    def add_dependency_edges():
        print("ğŸ”¹ æ·»åŠ  TO ä¾èµ–å…³ç³»...")
        query = select(GetObjectRelation.from_obj_id, GetObjectRelation.to_obj_id)
        relations = session.execute(query).all()
        for rel in relations:
            graph.add_edge(rel.from_obj_id, rel.to_obj_id, type='TO')
        print(f"âœ… å½“å‰æ€»è¾¹æ•°ï¼š{graph.number_of_edges()}")

    def impact_analyse():
        print("ğŸ” å¼€å§‹ä¸‹æ¸¸å½±å“åˆ†æï¼ˆå…¨è·¯å¾„ï¼‰...")
        count = 0

        for obj_id in graph.nodes:
            count += 1
            try:
                # è·å–æ‰€æœ‰ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆä¸å«è‡ªèº«ï¼‰
                downstream_nodes = nx.descendants(graph, obj_id)
                decendant_ids = [int(n) for n in downstream_nodes]

                record = ObjectImpact(
                    obj_id=obj_id,
                    decendant_ids=decendant_ids
                )
                session.add(record)

                if count % 100 == 0:
                    session.commit()

            except Exception as e:
                print(f"[â—] èŠ‚ç‚¹ {obj_id} åˆ†æå¤±è´¥: {e}")
                session.rollback()

        session.commit()
        print(f"ğŸ¯ å…±å¤„ç† {count} ä¸ª JOB èŠ‚ç‚¹ï¼Œå·²å†™å…¥ object_impact è¡¨ã€‚")

    def save_graph():

        folder_path = os.path.join(os.path.dirname(__file__), "graph_query")

        # å°†èŠ‚ç‚¹ä¿¡æ¯è½¬æ¢ä¸º DataFrame
        node_data = pd.DataFrame.from_dict(dict(graph.nodes(data=True)), orient="index")
        node_data.reset_index(inplace=True)
        node_data.rename(columns={"index": "node_id"}, inplace=True)

        # å°†è¾¹ä¿¡æ¯è½¬æ¢ä¸º DataFrame
        edge_data = nx.to_pandas_edgelist(graph)

        # ä¿å­˜ä¸º Parquet æ–‡ä»¶
        node_data.to_parquet(os.path.join(folder_path, "nodes.parquet"), index=False)
        edge_data.to_parquet(os.path.join(folder_path, "edges.parquet"), index=False)

    def read_graph():
        folder_path = os.path.join(os.path.dirname(__file__), "graph_query")
        nodes_df = pd.read_parquet(os.path.join(folder_path, "nodes.parquet"))
        edges_df = pd.read_parquet(os.path.join(folder_path, "edges.parquet"))

        # æ„å»º NetworkX å›¾
        G_new = nx.from_pandas_edgelist(edges_df, source="source", target="target", edge_attr=True)
        for _, row in nodes_df.iterrows():
            node_id = row["node_id"]
            G_new.add_node(node_id)
            G_new.nodes[node_id].update(row.drop("node_id").to_dict())

        # å¯¼å‡º GraphML
        graphml_path = os.path.join(folder_path, "graph.graphml")
        nx.write_graphml(G_new, graphml_path)
        print(f"âœ… graphml å¯¼å‡ºå®Œæˆï¼š{graphml_path}")

        # ä½¿ç”¨ py2neo åŒæ­¥å›¾åˆ° Neo4j
        graph = Graph("bolt://10.124.160.153:7687", auth=("neo4j", "password123"))

        # å¯é€‰ï¼šæ¸…ç©ºæ—§æ•°æ®
        graph.run("MATCH (n) DETACH DELETE n")

        # åˆ›å»ºèŠ‚ç‚¹
        for node_id, attrs in G_new.nodes(data=True):
            label = attrs.get("obj_app", "Node")  # å¦‚æœæœ‰ label å­—æ®µå°±ç”¨å®ƒï¼Œå¦åˆ™ç»Ÿä¸€ä½¿ç”¨ Node
            node = Node(label, id=str(node_id), **{k: str(v) for k, v in attrs.items() if k != "obj_app"})
            graph.merge(node, label, "id")  # é˜²æ­¢é‡å¤å¯¼å…¥

        # åˆ›å»ºå…³ç³»
        for source, target, attrs in G_new.edges(data=True):
            source_id, target_id = str(source), str(target)
            source_node = graph.nodes.match(id=source_id).first()
            target_node = graph.nodes.match(id=target_id).first()

            if source_node and target_node:
                rel_type = attrs.get("type", "RELATED_TO")
                rel_props = {k: str(v) for k, v in attrs.items()}
                rel = Relationship(source_node, rel_type, target_node, **{k: str(v) for k, v in attrs.items() if k != "type"})

                graph.merge(rel)

        print("ğŸ“Š å›¾ç»“æ„å·²åŒæ­¥è‡³ Neo4j")
        print("èŠ‚ç‚¹æ•°ï¼š", G_new.number_of_nodes(), "è¾¹æ•°ï¼š", G_new.number_of_edges())


    def transform_to_graph():
        print("\nğŸš€ å¯åŠ¨å›¾è½¬æ¢æµç¨‹ï¼ˆNetworkX + PostgreSQLï¼‰")
        add_all_nodes()
        add_folder_edges()
        add_dependency_edges()
        impact_analyse()  # å¦‚éœ€å¯å¼€å¯
        save_graph()
        print("ğŸ‰ å›¾ç»“æ„æ„å»ºå®Œæˆ")

    # transform_to_graph()
    read_graph()

def generate_config_file(
        sub_application_filter: list[str] | None = None,
        attributes_to_delete: list[str] = [],
        attributes_to_update: dict[str, str] = {},
        job_filter: str | None = None,
        output_file: str = "output_config.xml"
):
    """
    ä»æ•°æ®åº“è·å–Control-Mé…ç½®æ•°æ®å¹¶ç”Ÿæˆæ–°çš„XMLé…ç½®æ–‡ä»¶ã€‚
    æ”¯æŒæŒ‰å­åº”ç”¨ç¨‹åºç­›é€‰ã€å±æ€§æ›´æ–°å’Œåˆ é™¤ã€ä½œä¸šä¾èµ–é“¾è¿‡æ»¤ç­‰åŠŸèƒ½ã€‚

    :param sub_application_filter: æŒ‰SUB_APPLICATIONç­›é€‰folder, smart_folder, sub_folder, job
    :param attributes_to_delete: éœ€è¦æ‰¹é‡åˆ é™¤çš„å±æ€§ååˆ—è¡¨
    :param attributes_to_update: éœ€è¦æ‰¹é‡æ›´æ–°çš„å±æ€§å€¼å­—å…¸ï¼Œæ ¼å¼ä¸º{attribute_name: new_value}
    :param job_filter: ä½œä¸šåç§°è¿‡æ»¤å™¨ï¼Œåªå¯¼å‡ºæŒ‡å®šä½œä¸šåŠå…¶ä¾èµ–é“¾
    :param output_file: è¾“å‡ºçš„XMLæ–‡ä»¶è·¯å¾„
    """
    # åˆå§‹åŒ–å‚æ•°é»˜è®¤å€¼
    if attributes_to_delete is None:
        attributes_to_delete = []
    if attributes_to_update is None:
        attributes_to_update = {}

    # æ„å»ºåŸºç¡€æŸ¥è¯¢
    # æŸ¥è¯¢æ¡ä»¶ï¼šé€‰æ‹©DEFTABLE/WORKSPACEç±»å‹çš„å¯¹è±¡ï¼Œæˆ–è€…åŒ¹é…æŒ‡å®šå­åº”ç”¨ç¨‹åºçš„å¯¹è±¡
    query = (
        select(ControlMObjectWithAttr)
        .where(
            or_(
                ControlMObjectWithAttr.object_type.in_(['DEFTABLE', 'WORKSPACE']),
                ControlMObjectWithAttr.sub_application.in_(sub_application_filter) if sub_application_filter else True,
            )
        )
    )

    # æ‰§è¡ŒæŸ¥è¯¢è·å–å¯¹è±¡åˆ—è¡¨
    objects = session.execute(query)

    # å¦‚æœæŒ‡å®šäº†ä½œä¸šè¿‡æ»¤å™¨ï¼Œè·å–è¯¥ä½œä¸šçš„ä¾èµ–é“¾
    filter_id_list = []
    if job_filter:
        # è°ƒç”¨å­˜å‚¨è¿‡ç¨‹è·å–ä¾èµ–é“¾IDåˆ—è¡¨
        query_filter = text("SELECT id FROM parser.get_dependency_chain('" + job_filter + "','" + ",".join(
            sub_application_filter) + "') order by id;")
        filter_list = session.execute(query_filter)
        # æå–IDåˆ—è¡¨
        filter_id_list = [id[0] for id in filter_list]

    # åˆå§‹åŒ–XMLæ ‘ç»“æ„
    root = ET.Element("ROOT")
    # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„å¯¹è±¡ID
    selected_ids = set()
    # è®°å½•å¤„ç†çš„å¯¹è±¡æ•°é‡
    selected_count = 0

    def attr_value_check(value):
        """æ£€æŸ¥å¹¶å¤„ç†å±æ€§å€¼é•¿åº¦
        å¦‚æœå±æ€§å€¼é•¿åº¦è¶…è¿‡64ï¼Œåˆ™æˆªæ–­å‰3ä¸ªå­—ç¬¦

        :param value: åŸå§‹å±æ€§å€¼
        :return: å¤„ç†åçš„å±æ€§å€¼
        """
        result = value
        if len(value) >= 64:
            result = value[3:]
        return result

    def process_object(obj, parent_element):
        """
        å¤„ç†å•ä¸ªControl-Må¯¹è±¡ï¼Œå°†å…¶è½¬æ¢ä¸ºXMLå…ƒç´ å¹¶æ·»åŠ åˆ°çˆ¶å…ƒç´ ä¸­ã€‚
        åŒ…å«å¯¹è±¡è¿‡æ»¤ã€å±æ€§å¤„ç†å’Œé€’å½’å¤„ç†å­å¯¹è±¡çš„é€»è¾‘ã€‚

        :param obj: Control-Må¯¹è±¡å®ä¾‹
        :param parent_element: çˆ¶XMLå…ƒç´ 
        """
        nonlocal selected_count

        # é˜²æ­¢é‡å¤å¤„ç†åŒä¸€å¯¹è±¡
        if obj.id in selected_ids:
            return

        # ç¡®ä¿çˆ¶å¯¹è±¡å·²ç»è¢«å¤„ç†ï¼ˆç»´æŠ¤å¯¹è±¡å±‚çº§å…³ç³»ï¼‰
        if obj.parent_id and not obj.parent_id in selected_ids:
            return

        # è·å–å¯¹è±¡çš„æ‰€æœ‰å±æ€§
        attr_dict = obj.json_object_agg

        # æ³¨ï¼šå­åº”ç”¨ç¨‹åºè¿‡æ»¤å·²åœ¨SQLæŸ¥è¯¢ä¸­å®ç°
        # if sub_application_filter and attr_dict.get('SUB_APPLICATION') != sub_application_filter:
        #     if obj.object_type in ['SMART_FOLDER', 'JOB', 'FOLDER', 'SUB_FOLDER']:
        #         return  # SMART_FOLDER,JOB åªæå–ç­›é€‰æ¡ä»¶å†…çš„èŒƒå›´

        # ä½œä¸šè¿‡æ»¤ï¼šåªå¤„ç†æŒ‡å®šä½œä¸šåŠå…¶ä¾èµ–é“¾
        if job_filter and obj.object_type in ['JOB'] and obj.id not in filter_id_list:
            return

        # æ’é™¤ç‰¹å®šç±»å‹çš„ä½œä¸š
        if obj.object_type == 'JOB' and attr_dict.get('APPL_TYPE') == 'DAYUJOB':
            return

        # åˆ›å»ºæ–°çš„XMLå…ƒç´ 
        element = ET.SubElement(parent_element, obj.object_type)

        # å¤„ç†å¯¹è±¡çš„å±æ€§
        for attr, value in attr_dict.items():
            # è·³è¿‡éœ€è¦åˆ é™¤çš„å±æ€§
            if attr in attributes_to_delete:
                continue

            if obj.object_type in ['JOB', 'SMART_FOLDER', 'SUB_FOLDER'] and attr == 'JOBNAME':
                value = attr_value_check(value + attributes_to_update)

            elif obj.object_type == 'FOLDER' and attr == 'FOLDER_NAME':
                value = attr_value_check(value + attributes_to_update)

            elif obj.object_type in ['INCOND', 'OUTCOND'] and attr == 'NAME':
                cond_list = [attr_value_check(cond + attributes_to_update) for cond in value.split('-TO-')]
                value = '-TO-'.join(cond_list)

            element.set(attr, value)

        # è®°å½•é€‰å–çš„å…ƒç´  ID å’Œæ•°é‡
        selected_ids.add(obj.id)
        selected_count += 1

        query_for_child = query.filter(ControlMObjectWithAttrDepend.parent_id == obj.id)
        children = session.execute(query_for_child)

        # é€’å½’å¤„ç†å­å…ƒç´ 
        for child in children:
            process_object(child[0], element)

    def xml_element_process(parent_element, element, new_root_name):
        """
        å¤„ç†XMLå…ƒç´ çš„ç»“æ„è½¬æ¢ï¼ŒåŒ…æ‹¬æ–‡ä»¶å¤¹ç±»å‹è½¬æ¢ã€å±æ€§æ›´æ–°å’Œæ¸…ç†ã€‚

        :param parent_element: çˆ¶XMLå…ƒç´ 
        :param element: å½“å‰å¤„ç†çš„XMLå…ƒç´ 
        :param new_root_name: æ–°çš„æ ¹æ–‡ä»¶å¤¹åç§°
        """
        # ç§»é™¤æ²¡æœ‰ä½œä¸šçš„æ–‡ä»¶å¤¹å…ƒç´ 
        if element.tag in ['SUB_FOLDER', 'SMART_FOLDER', 'FOLDER'] and not 'JOB' in [child.tag for child in element]:
            parent_element.remove(element)
            return

        # å¤„ç†ä½œä¸šå’Œå­æ–‡ä»¶å¤¹çš„çˆ¶æ–‡ä»¶å¤¹è·¯å¾„
        if element.tag in ['JOB', 'SUB_FOLDER']:
            # æ›´æ–°çˆ¶æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ·»åŠ å±æ€§æ›´æ–°åç¼€
            element.attrib['PARENT_FOLDER'] = new_root_name + '/' + '/'.join(
                [path + attributes_to_update for path in element.attrib['PARENT_FOLDER'].split('/')])
            # åˆ é™¤å¾ªç¯ç›¸å…³çš„å±æ€§
            for attr in element.attrib:
                if attr in ['CYCLIC_TIMES_SEQUENCE', 'CYCLIC_TOLERANCE', 'CYCLIC_TYPE', 'IND_CYCLIC', 'CYCLIC']:
                    del element.attrib[attr]

        # å°†SMART_FOLDERå’ŒFOLDERè½¬æ¢ä¸ºSUB_FOLDER
        if element.tag in ['SMART_FOLDER', 'FOLDER']:
            # ä¿®æ”¹å…ƒç´ ç±»å‹
            element.tag = 'SUB_FOLDER'
            # è®¾ç½®çˆ¶æ–‡ä»¶å¤¹è·¯å¾„
            element.attrib['PARENT_FOLDER'] = attr_value_check(new_root_name)

            # è®¾ç½®åˆ›å»ºè€…æ ‡è®°
            element.set('CREATED_BY', 'inport')

            # åªä¿ç•™æŒ‡å®šçš„å±æ€§ï¼Œåˆ é™¤å…¶ä»–å±æ€§
            allowed_attrs = [
                'JOBISN', 'APPLICATION', 'SUB_APPLICATION', 'JOBNAME', 'CREATED_BY', 'RUN_AS', 'CRITICAL',
                'TASKTYPE', 'CYCLIC', 'INTERVAL', 'CONFIRM', 'RETRO', 'MAXWAIT', 'MAXRERUN', 'AUTOARCH',
                'MAXDAYS', 'MAXRUNS', 'DAYS', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP',
                'OCT', 'NOV', 'DEC', 'DAYS_AND_OR', 'PARENT_FOLDER'
            ]
            # åˆ é™¤ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­çš„å±æ€§
            for attr in list(element.attrib.keys()):
                if attr not in allowed_attrs:
                    del element.attrib[attr]

        # é€’å½’å¤„ç†æ‰€æœ‰å­å…ƒç´ 
        for child in element:
            xml_element_process(element, child, new_root_name)

    # ä»æ ¹èŠ‚ç‚¹å¼€å§‹å¤„ç†æ‰€æœ‰å¯¹è±¡
    for obj in objects:
        if not obj[0].parent_id:  # åªå¤„ç†æ ¹èŠ‚ç‚¹ï¼Œå­èŠ‚ç‚¹é€šè¿‡é€’å½’å¤„ç†
            process_object(obj[0], root)

    # åˆ›å»ºXMLæ ‘ç»“æ„
    tree = ET.ElementTree(root)

    # è·å–DEFTABLEèŠ‚ç‚¹ä½œä¸ºçˆ¶æ–‡ä»¶å¤¹
    parent_folder = tree.find('DEFTABLE')
    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å”¯ä¸€æ ‡è¯†
    current_unix_time = '_' + str(int(time.time()))

    # ä¸ºæ¯ä¸ªå­åº”ç”¨ç¨‹åºåˆ›å»ºç‹¬ç«‹çš„æ–‡ä»¶å¤¹
    for sub_application in sub_application_filter:
        # åˆ›å»ºæ–°çš„æ™ºèƒ½æ–‡ä»¶å¤¹
        one_time_folder = ET.Element("SMART_FOLDER")
        # è®¾ç½®åŸºæœ¬å±æ€§
        one_time_folder.set('APPLICATION', 'CMSK')
        one_time_folder.set('SUB_APPLICATION', sub_application)
        one_time_folder.set('RUN_AS', sub_application)
        # è®¾ç½®æ–‡ä»¶å¤¹æ ‡è¯†ï¼Œä½¿ç”¨å­åº”ç”¨ç¨‹åºåç§°åŠ æ—¶é—´æˆ³
        folder_identifier = sub_application + current_unix_time
        one_time_folder.set('PARENT_FOLDER', folder_identifier)
        one_time_folder.set('JOBNAME', folder_identifier)
        one_time_folder.set('FOLDER_NAME', folder_identifier)
        # è®¾ç½®ç‰ˆæœ¬å’Œç¯å¢ƒç›¸å…³å±æ€§
        one_time_folder.set('VERSION_HOST', '100.65.250.72, 100.73.29.67, 100.73.56.60')
        one_time_folder.set('IS_CURRENT_VERSION', 'Y')
        one_time_folder.set('DATACENTER', 'controlm')
        one_time_folder.set('VERSION_OPCODE', 'N')
        one_time_folder.set('VERSION', '919')
        # è®¾ç½®æ–‡ä»¶å¤¹è¡Œä¸ºå±æ€§
        one_time_folder.set('FOLDER_ORDER_METHOD', 'SYSTEM')
        one_time_folder.set('ENFORCE_VALIDATION', 'N')
        one_time_folder.set('RULE_BASED_CALENDAR_RELATIONSHIP', 'O')
        one_time_folder.set('CREATED_BY', 'inport')

        # å°†åŒ¹é…çš„å­åº”ç”¨ç¨‹åºå…ƒç´ ç§»åŠ¨åˆ°æ–°æ–‡ä»¶å¤¹
        for folder_like_element in parent_folder:
            if folder_like_element.attrib.get('SUB_APPLICATION') and folder_like_element.attrib[
                'SUB_APPLICATION'] == sub_application:
                one_time_folder.append(folder_like_element)

        # å°†æ–°æ–‡ä»¶å¤¹æ·»åŠ åˆ°çˆ¶æ–‡ä»¶å¤¹
        parent_folder.append(one_time_folder)

        # åˆ›å»ºå¹¶é…ç½®åŸºäºè§„åˆ™çš„æ—¥å†
        RULE_BASED_CALENDAR = ET.SubElement(one_time_folder, 'RULE_BASED_CALENDAR')
        RULE_BASED_CALENDAR.set('NAME', 'none')
        RULE_BASED_CALENDAR.set('MAXWAIT', '0')
        # è®¾ç½®æ‰€æœ‰æœˆä»½çš„é»˜è®¤å€¼ä¸º1
        for attr in ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']:
            RULE_BASED_CALENDAR.set(attr, '1')

        # é€’å½’å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å…ƒç´ 
        for element in one_time_folder:
            xml_element_process(one_time_folder, element, one_time_folder.attrib['JOBNAME'])

    # å°†å¤„ç†åçš„XMLå†™å…¥æ–‡ä»¶
    with open(output_file, "wb") as f:
        f.write(ET.tostring(parent_folder, pretty_print=True, xml_declaration=True, encoding="utf-8"))

    # æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„å¯¹è±¡
    all_object_ids = {obj.id for obj in objects}
    missing_ids = all_object_ids - selected_ids
    if missing_ids:
        print(f"Warning: Some objects were not processed. Missing IDs: {missing_ids}")

    # è¾“å‡ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯
    print(f"Selected {selected_count} elements with IDs: {selected_ids}")


if __name__ == '__main__':
    def parse_init():
        """åˆå§‹åŒ–å‡½æ•°ï¼šè§£æXMLæ–‡ä»¶å¹¶å¯¼å…¥æ•°æ®åº“"""
        start_time = time.time()
        # æ„å»ºXMLæ–‡ä»¶è·¯å¾„
        file_path = os.path.join(os.path.dirname(__file__), "asset", "Workspace_223.xml")
        # æ‰§è¡Œè§£æå’Œå¯¼å…¥
        parse_xml_to_db(file_path=file_path, batch_size=10000)
        # è®¡ç®—å¹¶æ‰“å°å¤„ç†æ—¶é—´
        end_time = time.time()
        print(f"å¤„ç†æ—¶é—´: {end_time - start_time} ç§’")


    def custom_generate():
        """è‡ªå®šä¹‰ç”Ÿæˆå‡½æ•°ï¼šæ ¹æ®ç‰¹å®šæ¡ä»¶ç”Ÿæˆæ–°çš„é…ç½®æ–‡ä»¶"""
        start_time = time.time()
        # ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®šè¿‡æ»¤æ¡ä»¶å’Œæ›´æ–°è§„åˆ™
        generate_config_file(
            sub_application_filter=[],  # ä¸é™åˆ¶å­åº”ç”¨ç¨‹åº
            # attributes_to_delete=["ATTRIBUTE1", "ATTRIBUTE2"],  # å¯é€‰ï¼šæŒ‡å®šè¦åˆ é™¤çš„å±æ€§
            attributes_to_update='_G',  # å±æ€§æ›´æ–°åç¼€
            job_filter='JOB_DWD_F_FITB_FIN_PLAN_CS_CD',  # æŒ‡å®šä½œä¸šè¿‡æ»¤å™¨
            output_file="output_config.xml"  # è¾“å‡ºæ–‡ä»¶å
        )
        # è®¡ç®—å¹¶æ‰“å°å¤„ç†æ—¶é—´
        end_time = time.time()
        print(f"å¤„ç†æ—¶é—´: {end_time - start_time} ç§’")


    # å–æ¶ˆæ³¨é‡Šä»¥æ‰§è¡Œç›¸åº”åŠŸèƒ½
    parse_init()
    # custom_generate()
    # å°†å¯¹è±¡å…³ç³»è½¬å­˜è‡³pg age
    # transform_to_graph()
    # ç”¨äºé…ç½®æ–‡ä»¶å¯¹æ¯”çš„åŠŸèƒ½ï¼ˆå·²æ³¨é‡Šï¼‰
    # compare_xml_files( './output_config.xml', '../asset/Workspace_256.txt')
